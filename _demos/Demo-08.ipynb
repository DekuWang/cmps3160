{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 08 - Predictive Models: Regression\n",
    "\n",
    "In this notebook we look at the basics of how to do a linear regression using various Python modules. We don't do gradient descent directly because it's easier to just use modules!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, mount your google drive, change to the course folder, pull latest changes, and change to the lab folder.\n",
    "# Startup Magic to: (1) Mount Google Drive\n",
    "# (2) Change to Course Folder\n",
    "# (3) Pull latest Changes\n",
    "# (4) Move to the Demo Directory so that the data files are available\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/My Drive/cmps3160\n",
    "!git pull\n",
    "%cd _demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes and Standard Magic...\n",
    "### Standard Magic and startup initializers.\n",
    "\n",
    "# Load Numpy\n",
    "import numpy as np\n",
    "# Load MatPlotLib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Load Pandas\n",
    "import pandas as pd\n",
    "# Load SQLITE\n",
    "import sqlite3\n",
    "# Load Stats\n",
    "from scipy import stats\n",
    "\n",
    "# This lets us show plots inline and also save PDF plots if we want them\n",
    "%matplotlib inline\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "\n",
    "# These two things are for Pandas, it widens the notebook and lets us display data easily.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# Show a ludicrus number of rows and columns\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Understanding the Data\n",
    "\n",
    "For this work we will be using data from: Generalized body composition prediction equation for men using simple measurement techniques\", K.W. Penrose, A.G. Nelson, A.G. Fisher, FACSM, Human Performance research Center, Brigham Young University, Provo, Utah 84602 as listed in Medicine and Science in Sports and Exercise, vol. 17, no. 2, April 1985, p. 189.\n",
    "\n",
    "[Data availabe here.](http://staff.pubhealth.ku.dk/~tag/Teaching/share/data/Bodyfat.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Penrose Data and have a look\n",
    "df_penrose = pd.read_csv(\"./data/bodyfat.csv\")\n",
    "display(df_penrose.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bit much so let's only use a smaller part of the data for the moment.\n",
    "observations = ['Age', 'Neck', 'Forearm', 'Wrist']\n",
    "display(df_penrose[observations].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations do we have?\n",
    "\n",
    "len(df_penrose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some really basic scatter plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we iterate over the observations and see what we have.\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "for i,o in enumerate(observations):\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Ways to Find a Linear Regression\n",
    "\n",
    "Let's say we want to look at some linear regressions of single variables to see what is going on!  So let's plot some regression lines.  Note that there are at least a few different ways -- [linregress](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html), [polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html), and [statsmodels](https://www.statsmodels.org/stable/index.html).\n",
    "\n",
    "Here's a good article about it [Data science with Python: 8 ways to do linear regression and measure their speed](https://www.freecodecamp.org/news/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a basic Linear Regression on a Single Variable.\n",
    "# Note that linregress p-value is whether or not the slope is 0, not if the correlation is significant.\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df_penrose[o],\n",
    "                                                                   df_penrose['bodyfat'])\n",
    "\n",
    "    # Pack these into a nice title\n",
    "    diag_str = \"p-value =\" + str(round(p_value, 7)) \n",
    "        + \"\\n\" + \"r-value =\" + str(round(r_value, 7)) \n",
    "        + \"\\nstd err. =\" + str(round(std_err, 7))\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', title=diag_str, ax=ax[i])\n",
    "    \n",
    "    # Make points and line\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = slope * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, color='red')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the polyfit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to fit a linear model with PolyFit.\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    # Fit our curve\n",
    "    x1, intercept = np.polyfit(df_penrose[o],df_penrose['bodyfat'], 1)\n",
    "    \n",
    "    # Plot regular points\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])\n",
    "    \n",
    "    # Plot curve\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = x1 * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, ls='-', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Models? \n",
    "\n",
    "So far we have only looked at the linear case -- what happens if we try to fit a polynomial to this data?\n",
    "\n",
    "Why would we want to fit some higher order polynomial on this data? Why is it a good idea or a bad idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try fitting a degree 2 polynomial with polyfit.\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    \n",
    "    # Fit the polynomial.\n",
    "    x2, x1, intercept = np.polyfit(df_penrose[o],df_penrose['bodyfat'], 2)\n",
    "\n",
    "    # Plot our points.\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])\n",
    "    \n",
    "    # Plot the Regression Line..\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = x2 * pts**2 + x1 * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, ls='-', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try fitting a degree 5 polynomial with polyfit.\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    \n",
    "    # Fit the polynomial.\n",
    "    x5, x4, x3, x2, x1, intercept = np.polyfit(df_penrose[o],df_penrose['bodyfat'], 5)\n",
    "\n",
    "    # Plot our points.\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])\n",
    "    \n",
    "    # Plot the Regression Line..\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = x5 * pts**5 + x4 * pts**4 + x3 * pts**3 + x2 * pts**2 + x1 * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, ls='-', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions and Plots with StatsModels and Seaborn\n",
    "\n",
    "Statsmodels (you'll likely need to install it) gives a much more R-like interface to linear modeling.  You can read [more about it here](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "df_ind = df_penrose[['Neck', 'Wrist']]\n",
    "df_target = df_penrose['bodyfat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ind\n",
    "y = df_target\n",
    "\n",
    "# Note the difference in argument order\n",
    "# Call: endog, then exog (dependent, indepenednt)\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "# Print out the statistics\n",
    "model.summary()\n",
    "#fig, ax = plt.subplots(figsize=(12,8))\n",
    "#fig = sm.graphics.plot_partregress(endog=\"bodyfat\", exog_i=['Abdomen', 'Neck'], exog_others='', data=df_penrose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the [single regressor plot](https://tedboy.github.io/statsmodels_doc/generated/statsmodels.graphics.api.plot_partregress.html#statsmodels.graphics.api.plot_partregress)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_partregress\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_partregress(endog='bodyfat', exog_i='Neck', exog_others='', data=df_penrose, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have multiple elements in our regression then we need to use a different plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression plot\n",
    "from statsmodels.graphics.regressionplots import plot_partregress_grid\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plot_partregress_grid(model, fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to work with regressions and their plots is using the [Seaborn Regression Package](https://seaborn.pydata.org/tutorial/regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to do simple exploratory plots\n",
    "import seaborn as sns\n",
    "df_test = df_penrose.sample(frac=0.10, replace=False)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    sns.regplot(x=o, y='bodyfat', data=df_test, ax=ax[i])\n",
    "    #g.axes.set_xlim(df_test[o].min()*.95,df_test[o].max()*1.05)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we saw before we can also use the sns pairplot.\n",
    "sns.pairplot(df_penrose[observations])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressions and the Bias v. Variance Tradeoff\n",
    "\n",
    "Another nice simulator to play with is [this one](https://ndirienzo.shinyapps.io/linear_regression_sim/) which is from [Prof. Nicholas DiRienzo](https://ischool.arizona.edu/people/nicholas-dirienzo) from ASU's School of Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We can use sklearn to do a quick logistic regression.  Remember that for logistic regression we are testing whether or not something is true, so we need to add a variable to our data.\n",
    "\n",
    "Someone is obese if their body fat is >32% so we'll add a dummy for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penrose['obese'] = df_penrose.apply(lambda x: 1 if x['bodyfat'] > 32 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to use sklearn to build us a classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# setup our data for testing and training.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_penrose[observations],\n",
    "                                                    df_penrose['obese'],\n",
    "                                                    test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit that model!\n",
    "logisticRegr = LogisticRegression(max_iter=100000, class_weight='balanced') \n",
    "model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot!\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy Score is: {accuracy_score(y_test, y_pred)}\")\n",
    "plot_confusion_matrix(model, X_test, y_test,\n",
    "                                 display_labels=logisticRegr.classes_,\n",
    "                                 cmap=plt.cm.Blues, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
