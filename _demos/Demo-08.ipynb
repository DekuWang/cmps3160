{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression and Missing Data\n",
    "\n",
    "In this notebook we will look at the effects missing data can have on conclusions you can draw from data.  We will also go over some practical implementations for linear regressions in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes and Standard Magic...\n",
    "### Standard Magic and startup initializers.\n",
    "\n",
    "# Load Numpy\n",
    "import numpy as np\n",
    "# Load MatPlotLib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Load Pandas\n",
    "import pandas as pd\n",
    "# Load SQLITE\n",
    "import sqlite3\n",
    "# Load Stats\n",
    "from scipy import stats\n",
    "\n",
    "# This lets us show plots inline and also save PDF plots if we want them\n",
    "%matplotlib inline\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "\n",
    "# These two things are for Pandas, it widens the notebook and lets us display data easily.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# Show a ludicrus number of rows and columns\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this work we will be using data from: Generalized body composition prediction equation for men using simple measurement techniques\", K.W. Penrose, A.G. Nelson, A.G. Fisher, FACSM, Human Performance research Center, Brigham Young University, Provo, Utah 84602 as listed in Medicine and Science in Sports and Exercise, vol. 17, no. 2, April 1985, p. 189.\n",
    "\n",
    "[Data availabe here.](http://staff.pubhealth.ku.dk/~tag/Teaching/share/data/Bodyfat.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Penrose Data\n",
    "df_penrose = pd.read_csv(\"./data/bodyfat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_penrose.head())\n",
    "# observations = ['Neck', 'Chest', 'Abdomen', 'Hip', 'Thigh', 'Knee', 'Ankle', 'Biceps', 'Forearm', 'Wrist']\n",
    "observations = ['Age', 'Neck', 'Forearm', 'Wrist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_penrose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some really basic scatter plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to look at some linear regressions of single variables to see what is going on!  So let's plot some regression lines.  Note that there are at least a few different ways -- [linregress](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html), [polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html), and [statsmodels](https://www.statsmodels.org/stable/index.html).\n",
    "\n",
    "Here's a good article about it [Data science with Python: 8 ways to do linear regression and measure their speed](https://www.freecodecamp.org/news/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a basic Linear Regression on a Single Variable.\n",
    "# Note that linregress p-value is whether or not the slope is 0, not if the correlation is significant.\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df_penrose[o],\n",
    "                                                                   df_penrose['bodyfat'])\n",
    "\n",
    "    # Pack these into a nice title\n",
    "    diag_str = \"p-value =\" + str(round(p_value, 7)) + \"\\n\" + \"r-value =\" + str(round(r_value, 7)) + \"\\nstd err. =\" + str(round(std_err, 7))\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', title=diag_str, ax=ax[i])\n",
    "    \n",
    "    # Make points and line\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = slope * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, color='red')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the polyfit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to fit a linear model with PolyFit.\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    # Fit our curve\n",
    "    x1, intercept = np.polyfit(df_penrose[o],df_penrose['bodyfat'], 1)\n",
    "    \n",
    "    # Plot regular points\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])\n",
    "    \n",
    "    # Plot curve\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = x1 * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, ls='-', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try fitting a degree 2 polynomial with polyfit.\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    \n",
    "    # Fit the polynomial.\n",
    "    x2, x1, intercept = np.polyfit(df_penrose[o],df_penrose['bodyfat'], 2)\n",
    "\n",
    "    # Plot our points.\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])\n",
    "    \n",
    "    # Plot the Regression Line..\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = x2 * pts**2 + x1 * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, ls='-', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try fitting a degree 5 polynomial with polyfit.\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    \n",
    "    # Fit the polynomial.\n",
    "    x5, x4, x3, x2, x1, intercept = np.polyfit(df_penrose[o],df_penrose['bodyfat'], 5)\n",
    "\n",
    "    # Plot our points.\n",
    "    df_penrose.plot.scatter(x=o, y='bodyfat', ax=ax[i])\n",
    "    \n",
    "    # Plot the Regression Line..\n",
    "    pts = np.linspace(df_penrose[o].min(), df_penrose[o].max(), 500)\n",
    "    line = x5 * pts**5 + x4 * pts**4 + x3 * pts**3 + x2 * pts**2 + x1 * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, ls='-', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A More Complicated example with Statsmodels.\n",
    "\n",
    "Statsmodels (you'll likely need to install it) gives a much more R-like interface to linear modeling.  You can read [more about it here](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "df_ind = df_penrose[['Neck', 'Wrist']]\n",
    "df_target = df_penrose['bodyfat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ind\n",
    "y = df_target\n",
    "\n",
    "# Note the difference in argument order\n",
    "# Call: endog, then exog (dependent, indepenednt)\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "# Print out the statistics\n",
    "model.summary()\n",
    "#fig, ax = plt.subplots(figsize=(12,8))\n",
    "#fig = sm.graphics.plot_partregress(endog=\"bodyfat\", exog_i=['Abdomen', 'Neck'], exog_others='', data=df_penrose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the [single regressor plot](https://tedboy.github.io/statsmodels_doc/generated/statsmodels.graphics.api.plot_partregress.html#statsmodels.graphics.api.plot_partregress)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_partregress\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_partregress(endog='bodyfat', exog_i='Neck', exog_others='', data=df_penrose, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have multiple elements in our regression then we need to use a different plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression plot\n",
    "from statsmodels.graphics.regressionplots import plot_partregress_grid\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plot_partregress_grid(model, fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to work with regressions and their plots is using the [Seaborn Regression Package](https://seaborn.pydata.org/tutorial/regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to do simple exploratory plots\n",
    "import seaborn as sns\n",
    "df_test = df_penrose.sample(frac=0.10, replace=False)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    sns.regplot(x=o, y='bodyfat', data=df_test, ax=ax[i])\n",
    "    #g.axes.set_xlim(df_test[o].min()*.95,df_test[o].max()*1.05)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another nice simulator to play with is [this one](https://ndirienzo.shinyapps.io/linear_regression_sim/) which is from [Prof. Nicholas DiRienzo](https://ischool.arizona.edu/people/nicholas-dirienzo) from ASU's School of Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We can use sklearn to do a quick logistic regression.  Remember that for logistic regression we are testing whether or not something is true, so we need to add a variable to our data.\n",
    "\n",
    "Someone is obese if their body fat is >32% so we'll add a dummy for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penrose['obese'] = df_penrose.apply(lambda x: 1 if x['bodyfat'] > 32 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to use sklearn to build us a classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# setup our data for testing and training.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_penrose[observations],\n",
    "                                                    df_penrose['obese'],\n",
    "                                                    test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit that model!\n",
    "logisticRegr = LogisticRegression(max_iter=100000, class_weight='balanced') \n",
    "model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot!\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy Score is: {accuracy_score(y_test, y_pred)}\")\n",
    "plot_confusion_matrix(model, X_test, y_test,\n",
    "                                 display_labels=logisticRegr.classes_,\n",
    "                                 cmap=plt.cm.Blues, normalize='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would you do this again to test the various bits of the model?  Find out in Lab 9!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now back to Missing Data!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we start to remove parts of the data -- is the relationship still as strong?\n",
    "\n",
    "We can use the [pandas sample command](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) to remove some of the dataframe.\n",
    "\n",
    "Note that here we are just asking the question, if we took some of the data out randomly, do we still get the same result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's do a basic Linear Regression on a Single Variable.\n",
    "# Note that linregress p-value for the null-hyp that slope = 0.\n",
    "df_test = df_penrose.sample(frac=0.2, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "for i,o in enumerate(observations):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df_test[o],\n",
    "                                                                   df_test['bodyfat'])\n",
    "\n",
    "    # Pack these into a nice title\n",
    "    diag_str = \"p-value =\" + str(round(p_value, 7)) + \"\\n\" + \"r-value =\" + str(round(r_value, 7)) + \"\\nstd err. =\" + str(round(std_err, 7))\n",
    "    df_test.plot.scatter(x=o, y='bodyfat', title=diag_str, ax=ax[i])\n",
    "    \n",
    "    # Make points and line\n",
    "    pts = np.linspace(df_test[o].min(), df_test[o].max(), 500)\n",
    "    line = slope * pts + intercept\n",
    "    ax[i].plot(pts, line, lw=1, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to determine if these correlations are significant under the missing data then we need to run bootstrap samples and see what happens.\n",
    "\n",
    "Nick -- modify this to drop part of the data then resample from the dropped part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {o:[] for o in observations}\n",
    "bootstrap_samples = 1000\n",
    "fraction = 0.20\n",
    "\n",
    "for i,o in enumerate(observations):\n",
    "    for t in range(bootstrap_samples):\n",
    "        df_test = df_penrose.sample(frac=fraction, replace=False)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_test[o],df_test['bodyfat'])\n",
    "        #r,p = stats.pearsonr(df_test[o], df_test['bodyfat'])\n",
    "        results[o].append(p_value)\n",
    "        \n",
    "rs = pd.DataFrame(results)\n",
    "ax = rs.boxplot()\n",
    "ax.set_ylim([-0.01,0.30])\n",
    "ax.set_title(f\"p-value of 1 variable regression over {bootstrap_samples} iterations\")\n",
    "ax.set_ylabel(\"p-value\")\n",
    "ax.set_xlabel(\"Body Part\")\n",
    "ax.axhline(y=0.05, lw=2, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above as we run more and more samples and plot the p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
