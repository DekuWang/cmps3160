{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "In this notebook we'll use the famous [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/iris) to check out some real decision trees!  \n",
    "\n",
    "<img src=\"./data/iris.png\">\n",
    "\n",
    "This data set has:\n",
    "1. 150 instances with 4 attributes (same units, all numeric)\n",
    "2. Balanced class distribution\n",
    "3. No missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes and Standard Magic...\n",
    "### Standard Magic and startup initializers.\n",
    "\n",
    "# Load Numpy\n",
    "import numpy as np\n",
    "# Load MatPlotLib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Load Pandas\n",
    "import pandas as pd\n",
    "# Load SQLITE\n",
    "import sqlite3\n",
    "# Load Stats\n",
    "from scipy import stats\n",
    "\n",
    "# This lets us show plots inline and also save PDF plots if we want them\n",
    "%matplotlib inline\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# These two things are for Pandas, it widens the notebook and lets us display data easily.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data and check it out...\n",
    "df_iris = pd.read_csv(\"./data/iris.csv\")\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.groupby(\"species\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a test and train split.  Note that we are using a *stratified sample* here so that we don't mess up our classifier! [More info in the docs!](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the whole thing...\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_iris, \n",
    "                               test_size=0.4, \n",
    "                               stratify=df_iris[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that...\n",
    "train.groupby(\"species\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(\"species\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun..\n",
    "import seaborn as sns\n",
    "sns.pairplot(train, hue=\"species\", height=2, palette='colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()\n",
    "sns.heatmap(corrmat, annot = True, square = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "X_train = train[features]\n",
    "y_train = train.species\n",
    "X_test = test[features]\n",
    "y_test = test.species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "mod_dt.fit(X_train,y_train)\n",
    "prediction=mod_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some measures...\n",
    "print(f\"The accuracy of the Decision Tree is {metrics.accuracy_score(prediction,y_test):.3f}\")\n",
    "print(f\"The Precision of the Decision Tree is {metrics.precision_score(prediction,y_test,average='weighted'):.3f}\")\n",
    "print(f\"The Recall of the Decision Tree is {metrics.recall_score(prediction,y_test,average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some graphs...\n",
    "metrics.plot_confusion_matrix(mod_dt, X_test, y_test,\n",
    "                                 display_labels=mod_dt.classes_,\n",
    "                                 cmap=plt.cm.Blues, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooler...\n",
    "mod_dt.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plot_tree(mod_dt, feature_names = features, class_names = mod_dt.classes_, filled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Above only is using petal_width and petal_length... so we can plot the decision boundry.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens with the titanic dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv(\"./data/titanic.csv\")\n",
    "df_titanic = pd.get_dummies(df_titanic, columns=['sex'])\n",
    "# Be cheeky with our NAN\n",
    "df_titanic = df_titanic[(df_titanic[\"age\"].notna()) & (df_titanic[\"fare\"].notna())]\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_titanic, \n",
    "                               test_size=0.4, \n",
    "                               stratify=df_titanic[\"survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"pclass\", \"fare\", \"sex_female\", \"age\"]\n",
    "X_train = train[features]\n",
    "y_train = train.survived\n",
    "X_test = test[features]\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "mod_dt.fit(X_train,y_train)\n",
    "prediction=mod_dt.predict(X_test)\n",
    "# Check some measures...\n",
    "print(f\"The accuracy of the Decision Tree is {metrics.accuracy_score(prediction,y_test):.3f}\")\n",
    "print(f\"The Precision of the Decision Tree is {metrics.precision_score(prediction,y_test,average='weighted'):.3f}\")\n",
    "print(f\"The Recall of the Decision Tree is {metrics.recall_score(prediction,y_test,average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some graphs...\n",
    "metrics.plot_confusion_matrix(mod_dt, X_test, y_test,\n",
    "                                 display_labels=[\"died\",\"survived\"],\n",
    "                                 cmap=plt.cm.Blues, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some graphs...\n",
    "metrics.plot_precision_recall_curve(mod_dt, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plot_tree(mod_dt, feature_names = features, class_names={1:\"survived\", 0:\"died\"}, filled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show the boundry (no plot)\n",
    "<img src=\"./data/boundry.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quick Note: Feature Engineering\n",
    "\n",
    "Sometimes we can't just use the features we have, we have to create a new feature from them.  This process is called feature enginnering.\n",
    "\n",
    "To demonstrate, let's make and try to predict some circles from just their x and y cordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_points = 100\n",
    "data = {\"x\": np.random.randint(1,100,100), \"y\": np.random.randint(1,100,100)}\n",
    "data['r'] = [np.sqrt(x**2 + y**2) for x,y in zip(data['x'],data['y'])]\n",
    "df_circles = pd.DataFrame(data)\n",
    "df_circles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles.plot.scatter(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Let's use a Linear Regression to try to predict r given x and y.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_circles[['x','y']], \n",
    "                                                    df_circles[\"r\"], \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(f'''Model Score: {reg.score(X_train, y_train):.3f} and Validation Score: {reg.score(X_test, y_test):.3f}.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good but we know the equation for a circle is $x^2 + y^2 = r^2$, so what happens if we add $x^2$ and $y^2$ to our data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles['x2'] = df_circles['x']**2\n",
    "df_circles['y2'] = df_circles['y']**2\n",
    "df_circles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and run again...\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_circles[['x', 'y','x2','y2']], \n",
    "                                                    df_circles[\"r\"], \n",
    "                                                    test_size=0.3)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(f'''Model Score: {reg.score(X_train, y_train):.3f} and Validation Score: {reg.score(X_test, y_test):.3f}.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
