{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you may have to install requests!  pip3 install requests\n",
    "\n",
    "import requests\n",
    "# These two things are for Pandas, it widens the notebook and lets us display data easily.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple API Call with Requests Library\n",
    "\n",
    "It may be good to look at the reference documentation for the [requests library](https://2.python-requests.org/en/master/user/quickstart/).\n",
    "\n",
    "First, let's have a look at the [GitHub API](https://developer.github.com/v3/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.github.com/users/nmattei', timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at HTTP Requests\n",
    "\n",
    "We'll try to get some data from Google.  Note that this is kind of against the TOS and we **should not do it this way in general -- Google has very [specific rules on their site](https://developers.google.com/custom-search/v1/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'q':'Tulane University'}\n",
    "r = requests.get('http://www.google.com/search', params = params, timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'q':'Tulane University'}\n",
    "r = requests.get('https://search.yahoo.com/', params = params, timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complicated with Parameters\n",
    "\n",
    "We'll look for some information from the [Apple ITunes API](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'term' : \"the+meters\"}\n",
    "r = requests.get('https://itunes.apple.com/search', params=params, timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do lots of parameters in the payload like [this](https://2.python-requests.org/en/master/user/quickstart/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'term' : \"the+meters\", 'entity' : 'album'}\n",
    "r = requests.get('https://itunes.apple.com/search', params=params, timeout=10)\n",
    "r.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x['results'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the returned JSON to an object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['results'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['results'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['results'][1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Beautiful Soup to Parse a Webpage.\n",
    "\n",
    "The [beautifulsoup4 documentation](https://www.crummy.com/software/BeautifulSoup/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the course webpage.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get('https://nmattei.github.io/cmps3160/schedule/')\n",
    "\n",
    "root = BeautifulSoup( r.content )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root.find(\"table\").findAll(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out some Regular Expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Find the index in the raw HTML where we first mention CMPS3160\n",
    "\n",
    "# Note we use the r to make sure special flags get used correctly.\n",
    "\n",
    "r = requests.get('https://nmattei.github.io/cmps3160/syllabus/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's see what we got.\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'CMPS 3160', r.text)\n",
    "print(match.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text[390:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the start match?\n",
    "match = re.match(r'CMPS 3160', r.text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all occurances and print a few characters.\n",
    "for m in re.finditer(r'CMPS 3160', r.text):\n",
    "    print(r.text[m.start()-50:m.start()+50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find them all and the word(s)? right after?\n",
    "match = re.findall(r'CMPS 3160\\s\\w*', r.text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we find all the email addresses?\n",
    "text = ''' This is a list that has an @ symbol in it.\n",
    "            But we want to find Nick's address nsmattei@tulane.edu\n",
    "            But also maybe someone else's eli@gmail.com....\n",
    "            How would we write a regex for that?\n",
    "\n",
    "\n",
    "            Also there is more text, and can't like \n",
    "            phil123@school.edu also be able to be caught?\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Need to test on a few first..\n",
    "# What rules do we need?\n",
    "regex = r'\\D\\w*@\\w+\\.\\w{3}'\n",
    "match = re.findall(regex, text)\n",
    "print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER for full email\n",
    "regex = r'\\w+@\\w+.\\w{3}'\n",
    "match = re.findall(regex, text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only names, no domains...\n",
    "regex = r'\\w+@'\n",
    "match = re.findall(regex, text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eli's more complicated answer with lookaheads\n",
    "regex = r\"[A-z]+(?=[^A-z\\s]*@)\"\n",
    "match = re.findall(regex, text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use this on the webpage!\n",
    "regex = r'\\w+@\\w+.\\w{3}'\n",
    "match = re.findall(regex, r.text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complicated RegExes - Groups\n",
    "regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(\\w{3,})'\n",
    "\n",
    "text = ''' The university of kentucky is the best\n",
    "            basketball team and an ok university. and University of North CC\n",
    "            The University Of Kentucky can be put in \n",
    "            some weird capitalization and University of Ken spelled wrong'''\n",
    "m = re.search( regex, text)\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all\n",
    "print(re.findall(regex, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Groups.\n",
    "regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(?P<school>\\w{3,})'\n",
    "text = ''' The university of kentucky is the best University of Lousiana\n",
    "            basketball team and an ok university.\n",
    "            The University Of Kentucky can be put in \n",
    "            some weird capitalization'''\n",
    "m = re.search( regex, text)\n",
    "print(m.groupdict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all named groups\n",
    "\n",
    "# Named Groups.\n",
    "regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(?P<school>\\w{3,})'\n",
    "text = ''' The university of kentucky is the best\n",
    "            basketball team and an ok university.\n",
    "            The University Of Kentucky can be put in \n",
    "            some weird capitalization.  And Kentucky is much better than\n",
    "            the University of Mississippi.'''\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m.groupdict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'abcabcabc'.replace('a', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I love Introduction to Data Science'\n",
    "re.sub(r'Data Science', r'Schmada Schmience', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'(\\w+)\\s([Ss]cience)', r'\\2 \\1hmience', text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use it to parse part of a CSV?\n",
    "text = '12,15,22,36,78,33,77,33,45'\n",
    "\n",
    "# Use Regex split command\n",
    "print(re.split(',', text))\n",
    "\n",
    "# Use string split command\n",
    "print(text.split(\",\"))\n",
    "\n",
    "#Use Regex to split into groups...\n",
    "regex = r'(?P<data>\\d*,)'\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m.groupdict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloadning All the ... PDFs from the course website.\n",
    "\n",
    "Using beautiful soup and some regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP GET request sent to the URL url\n",
    "# But our schedule is in an iframe... can we see that?\n",
    "r = requests.get( \"https://nmattei.github.io/cmps3160/schedule/\" )\n",
    "r.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HTTP GET request sent to the URL url\n",
    "# We're going to use John's webpage because IFrames cause lots of issues...\n",
    "r = requests.get( \"https://cmsc320.github.io/\" )\n",
    "r.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use BeautifulSoup to parse the GET response -- we want the second table on the page..\n",
    "root = BeautifulSoup( r.content )\n",
    "lnks = root.findAll(\"table\")\n",
    "lnks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use BeautifulSoup to parse the GET response -- we want the second table on the page..\n",
    "root = BeautifulSoup( r.content )\n",
    "lnks = root.findAll(\"table\")\n",
    "lnks[1].find(\"tbody\").findAll(\"a\")\n",
    "lnks = lnks[1].find(\"tbody\").findAll(\"a\")\n",
    "lnks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through the href for each anchor, checking\n",
    "# to see if it's a PDF/PPTX link or not\n",
    "pdfs = []\n",
    "for lnk in lnks:\n",
    "    href = lnk['href']\n",
    "    \n",
    "    # If it's a PDF/PPTX link, queue a download   \n",
    "    if href.lower().endswith(('.pdf', '.pptx')):\n",
    "        pdfs.append(href)\n",
    "        #print(\"{} is a Link to {}\".format(lnk.contents,lnk['href']))\n",
    "print(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Notice above we need to insert the base link...\n",
    "base_url = \"https://cmsc320.github.io/\"\n",
    "for href in pdfs:\n",
    "    urld = urljoin(base_url, href)\n",
    "    print(urld)\n",
    "    rd = requests.get(urld, stream=True)\n",
    "    \n",
    "    # Write the downloaded PDF to a file\n",
    "    # Note because the href is a path we have to just get the filename!\n",
    "    outfile = os.path.join(\"./\", href.split(\"/\")[-1])\n",
    "    print(\"Writing: \",outfile)\n",
    "    with open(outfile, 'wb') as f:\n",
    "        f.write(rd.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here is an example of how to do this off a GitHub page but it is sort of broken, use at your own risk..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the easier one first and download all the `.ipynb` from the webpage.  We'll get into why this is easier in a second..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through the href for each anchor, checking\n",
    "# to see if it's an ipynb link or not\n",
    "notebooks = []\n",
    "for lnk in lnks:\n",
    "    href = lnk['href']\n",
    "    # If it's a PDF/PPTX link, queue a download   \n",
    "    if href.lower().endswith(('ipynb')):\n",
    "        notebooks.append(href)\n",
    "        print(\"{} is a Link to {}\".format(lnk.contents,lnk['href']))\n",
    "print(notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the files to whatever you're running notebook from.\n",
    "\n",
    "# Be careful for href!\n",
    "\n",
    "for i, href in enumerate(notebooks):\n",
    "    print(\"Downloading... {}\".format(href))\n",
    "    rd = requests.get(href, stream=True)\n",
    "    \n",
    "    # Write the downloaded object to a file -- first we should make a directory for it..\n",
    "    outputdir = os.path.join(os.getcwd(), \"downloaded\")\n",
    "    os.makedirs(outputdir, exist_ok=True)\n",
    "    \n",
    "    # Note because the href is a path we have to just get the filename!\n",
    "    outfile = os.path.join(outputdir, href.split(\"/\")[-1])\n",
    "    print(\"Writing: \",outfile)\n",
    "    with open(outfile, 'wb') as f:\n",
    "        f.write(rd.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this more complicated and try to grab all the PDF's...\n",
    "\n",
    "First thing to note is that the PDFs have it in the name but not the target and they're hosted on GOOGLE! -- so this doesn't really work :-(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can go check, we get a google drive directory...\n",
    "\n",
    "r = requests.get( \"https://drive.google.com/drive/u/1/folders/1uGrhWzhXbiqoChTK0fQXg340X319REks\" )\n",
    "\n",
    "# Use BeautifulSoup to parse the GET response\n",
    "root = BeautifulSoup( r.content )\n",
    "#lnks = root.find(\"table\").findAll(\"a\")\n",
    "#lnks\n",
    "root.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have all google links so we need to check the tags to see if they contain PDF!\n",
    "pdfs = []\n",
    "for lnk in lnks:\n",
    "    if 'pdf' in lnk.contents[0].lower():\n",
    "        print(\"{} is a PDF Link to {}\".format(lnk.contents,lnk['href']))\n",
    "        pdfs.append(lnk['href'])\n",
    "print(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that google doens't make this easy... sorry, you have to do a little kung fu...\n",
    "# Format is: https://drive.google.com/u/1/uc?id=ID&export=download\n",
    "download_links = []\n",
    "for c in pdfs:\n",
    "    fid = c.split(\"/\")[-2]\n",
    "    download_links.append(\"https://drive.google.com/u/1/uc?id={}&export=download\".format(fid))\n",
    "print(download_links)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
