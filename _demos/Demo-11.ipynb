{"cells":[{"cell_type":"markdown","metadata":{"id":"vwFmMaa0pgQK"},"source":["# Demo 11 - Regular Expressions and Web Scraping\n","\n","In this notebook we look at the basics of the `requests` library, how to use regular expressions in Python, and grabbing information from the web using Beautiful Soup!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWUTm0xVpgQN"},"outputs":[],"source":["# first, mount your google drive, change to the course folder, pull latest changes, and change to the lab folder.\n","# Startup Magic to: (1) Mount Google Drive\n","# (2) Change to Course Folder\n","# (3) Pull latest Changes\n","# (4) Move to the Demo Directory so that the data files are available\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/cmps3160\n","!git pull\n","%cd _demos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9_MdVk1pgQO"},"outputs":[],"source":["# Note you may have to install requests!  pip3 install requests\n","import requests\n","# These two things are for Pandas, it widens the notebook and lets us display data easily.\n","from IPython.core.display import display, HTML\n","display(HTML(\"<style>.container { width:95% !important; }</style>\"))"]},{"cell_type":"markdown","metadata":{"id":"hCqIoAHMtBkM"},"source":["## Simple Webpage Call with Requests Library\n","\n","It may be good to look at the reference documentation for the [requests library](https://2.python-requests.org/en/master/user/quickstart/).\n","\n","First, let's have a look at the [PolitWoops](https://projects.propublica.org/politwoops/).\n","\n","Or even [Prof. Culotta's Website](https://cs.tulane.edu/~aculotta/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYs8pkuCvfAJ"},"outputs":[],"source":["r = requests.get('https://cs.tulane.edu/~aculotta/', timeout=10)\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuyqEizevfHe"},"outputs":[],"source":["r.headers['content-type']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIDMtgMkvfOC"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgduIp8PvloZ"},"outputs":[],"source":["# Note that this is the same as if we just got to the page!\n","r.content[:5000]"]},{"cell_type":"markdown","metadata":{"id":"E6pDs5e_vqYJ"},"source":["**Point:** A really great resource is to check out this page [What happens when you type google.com into the address bar](https://github.com/alex/what-happens-when) which goes through the whole stack!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTjkkheMtEzq"},"outputs":[],"source":["r = requests.get('https://projects.propublica.org/politwoops/', timeout=10)\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8XB9sYJtJhY"},"outputs":[],"source":["r.headers['content-type']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3DVNbVetJsJ"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpzLJ58vtJyY"},"outputs":[],"source":["r.content[:5000]"]},{"cell_type":"markdown","metadata":{"id":"oqa6y-GQpgQR"},"source":["## Looking at HTTP Requests\n","\n","We'll try to get some data from Google.  Note that this is kind of against the TOS and we **should not do it this way in general -- Google has very [specific rules on their site](https://developers.google.com/custom-search/v1/).**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0gT80UmpgQS"},"outputs":[],"source":["params = {'q':'Tulane University'}\n","headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:101.0) Gecko/20100101 Firefox/101.0'}\n","r = requests.get('http://www.google.com/search', params = params, headers=headers, timeout=10)\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAPGzGRkpgQS"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLJXvEPCtfWO"},"outputs":[],"source":["r.headers['content-type']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33weUwLlthg1"},"outputs":[],"source":["r.text[:5000]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This is a bit messy, let's use Beautiful Soup (we'll see this more later) to get just the text information.\n","from bs4 import BeautifulSoup\n","soup = BeautifulSoup( r.content )\n","print(soup.prettify()[:5000])\n","print(\"\\n\\nText only: \\n\\n\")\n","print(soup.get_text().split()[:50])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x25Hg36HpgQS"},"outputs":[],"source":["params = {'q':'Tulane University'}\n","r = requests.get('https://duckduckgo.com/', params = params, timeout=10)\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qQsESLipgQS"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78LMnWP_pgQT"},"outputs":[],"source":["r.headers['content-type']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYvlD4E6pgQT","scrolled":true},"outputs":[],"source":["r.text"]},{"cell_type":"markdown","metadata":{"id":"GdtYYhc4pgQP"},"source":["Well, that's lame because it basically just redirects to google :-)\n","\n","## Simple API Call with Requests Library\n","\n","It may be good to look at the reference documentation for the [requests library](https://2.python-requests.org/en/master/user/quickstart/).\n","\n","First, let's have a look at the [GitHub API](https://developer.github.com/v3/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdgGZVIMpgQP"},"outputs":[],"source":["r = requests.get('https://api.github.com/users/nmattei', timeout=10)\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wr9QFG_pgQQ"},"outputs":[],"source":["r.headers['content-type']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uXmXZCkpgQQ"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74wF7afHpgQQ"},"outputs":[],"source":["r.content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJQt5P6ipgQR","scrolled":false},"outputs":[],"source":["r.json()"]},{"cell_type":"markdown","metadata":{"id":"Uh2Mxz1MpgQT"},"source":["## More Complicated with Parameters\n","\n","We'll look for some information from the [Apple ITunes API](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bixuF7hFpgQT"},"outputs":[],"source":["params = {'term' : \"the+meters\"}\n","r = requests.get('https://itunes.apple.com/search', params=params, timeout=10)\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6VUUElBOpgQU"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9DcBAMJpgQU","scrolled":true},"outputs":[],"source":["r.json()"]},{"cell_type":"markdown","metadata":{"id":"ikvwBmnOpgQU"},"source":["We can do lots of parameters in the payload like [this](https://2.python-requests.org/en/master/user/quickstart/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dE1N-1VpgQU"},"outputs":[],"source":["params = {'term' : \"the+meters\", 'entity' : 'album'}\n","r = requests.get('https://itunes.apple.com/search', params=params, timeout=10)\n","r.status_code\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UHbbvXSpgQV"},"outputs":[],"source":["r.url"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlinLFKEpgQV","scrolled":true},"outputs":[],"source":["r.json()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XinrYugpgQV","scrolled":true},"outputs":[],"source":["x = r.json()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IY79RgcpgQV"},"outputs":[],"source":["type(x['results'][0])"]},{"cell_type":"markdown","metadata":{"id":"0ZnOnwFppgQV"},"source":["## Converting the returned JSON to an object!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsSI7DI4pgQV"},"outputs":[],"source":["import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULkOCDvxpgQV"},"outputs":[],"source":["data = json.loads(r.content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXJ_7TyTpgQW"},"outputs":[],"source":["data.keys()\n","data['results']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0933U13ipgQW"},"outputs":[],"source":["type(data['results'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zM5nSjxKpgQW"},"outputs":[],"source":["type(data['results'][1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ue1HtqnCpgQW"},"outputs":[],"source":["data['results'][1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHzxPLwmpgQW"},"outputs":[],"source":["data['results'][1].keys()"]},{"cell_type":"markdown","metadata":{},"source":["So that works really well to get a dict, but more importantly Pandas will convert this to a DataFrame for us!! More information in the [read_json() function](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-wTVPEoUzaDo"},"outputs":[],"source":["import pandas as pd\n","\n","df_t = pd.DataFrame.from_dict(data[\"results\"])\n","df_t"]},{"cell_type":"markdown","metadata":{"id":"A1jIfIDupgQW"},"source":["## Using Beautiful Soup to Parse a Webpage.\n","\n","The [beautifulsoup4 documentation](https://www.crummy.com/software/BeautifulSoup/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zwt46vapgQW"},"outputs":[],"source":["# Grab the course webpage.\n","import requests\n","from bs4 import BeautifulSoup\n","\n","r = requests.get('https://cs.tulane.edu/~aculotta/')\n","\n","soup = BeautifulSoup( r.content )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or_0F46NpgQX","scrolled":true},"outputs":[],"source":["r.content[:5000]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["soup.prettify()[:5000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5Haf8A3pgQX","scrolled":true},"outputs":[],"source":["soup.find(\"table\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpfJaT3gzBxS"},"outputs":[],"source":["# The above gets the first table, but there could be a lot more!\n","soup.findAll(\"table\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnxBDXkHpgQX","scrolled":true},"outputs":[],"source":["# Find all links!\n","\n","soup.find(\"table\").findAll(\"a\")"]},{"cell_type":"markdown","metadata":{},"source":["So we can use Pandas and BS4 together as well -- we'll see a lot more of this in the lab this week!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_tables = []\n","for t in soup.findAll(\"table\"):\n","    df_t = pd.read_html(str(t))\n","    df_tables.append(df_t[0])\n","\n","for t in df_tables:\n","    display(t)"]},{"cell_type":"markdown","metadata":{"id":"JtraUrSSpgQX"},"source":["## Trying out some Regular Expressions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HaKDgCT5pgQX"},"outputs":[],"source":["import re\n","# Find the index in the raw HTML where we first mention CMPS3160\n","\n","# Note we use the r to make sure special flags get used correctly.\n","\n","r = requests.get('https://nmattei.github.io/cmps3160/syllabus/')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdLvTtHOpgQX","scrolled":true},"outputs":[],"source":["# Let's see what we got.\n","r.text[:5000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-0n-JJfpgQY"},"outputs":[],"source":["match = re.search(r'CMPS 3160', r.text)\n","print(match.start())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"db1UAKo3pgQY"},"outputs":[],"source":["r.text[390:500]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed46sLwMpgQY"},"outputs":[],"source":["# Does the start match?\n","match = re.match(r'CMPS 3160', r.text)\n","print(match)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dG3Lvk6IpgQY"},"outputs":[],"source":["# Iterate over all occurances and print a few characters.\n","for m in re.finditer(r'CMPS 3160', r.text):\n","    print(r.text[m.start()-50:m.start()+50])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBXTiNwBpgQY"},"outputs":[],"source":["# Find them all and the word(s)? right after?\n","match = re.findall(r'CMPS 3160\\s\\w*', r.text)\n","print(match)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kGpW9K4IpgQY"},"outputs":[],"source":["# Can we find all the email addresses?\n","text = ''' This is a list that has an @ symbol in it.\n","            But we want to find Nick's address nsmattei@tulane.edu\n","            But also maybe someone else's eli@gmail.com....\n","            How would we write a regex for that?\n","\n","\n","            Also there is more text, and can't like \n","            phil123@school.edu also be able to be caught?\n","\n","\n","\n","'''\n","\n","# Need to test on a few first..\n","# What rules do we need?\n","regex = r'\\D\\w*@\\w+\\.\\w{3}'\n","match = re.findall(regex, text)\n","print(match)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BvDCfJLWpgQY"},"outputs":[],"source":["### ANSWER for full email\n","regex = r'\\w+@\\w+.\\w{3}'\n","match = re.findall(regex, text)\n","print(match)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Rq4YP6RpgQZ"},"outputs":[],"source":["### Only names, no domains...\n","regex = r'\\w+@'\n","match = re.findall(regex, text)\n","print(match)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkJR21_5pgQZ"},"outputs":[],"source":["## Eli's more complicated answer with lookaheads\n","regex = r\"[A-z]+(?=[^A-z\\s]*@)\"\n","match = re.findall(regex, text)\n","print(match)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAdgH8f7pgQZ"},"outputs":[],"source":["# Now we can use this on the webpage!\n","regex = r'\\w+@\\w+.\\w{3}'\n","match = re.findall(regex, r.text)\n","print(match)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YV91r37GpgQZ"},"outputs":[],"source":["# More complicated RegExes - Groups\n","regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(\\w{3,})'\n","\n","text = ''' The university of kentucky is the best\n","            basketball team and an ok university. and University of North CC\n","            The University Of Kentucky can be put in \n","            some weird capitalization and University of Ken spelled wrong'''\n","m = re.search( regex, text)\n","print(m.groups())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lb1RNJIFpgQZ"},"outputs":[],"source":["# Find all\n","print(re.findall(regex, text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gaaRqIwvpgQZ"},"outputs":[],"source":["# Named Groups.\n","regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(?P<school>\\w{3,})'\n","text = ''' The university of kentucky is the best University of Lousiana\n","            basketball team and an ok university.\n","            The University Of Kentucky can be put in \n","            some weird capitalization'''\n","m = re.search( regex, text)\n","print(m.groupdict())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJXiefyLpgQZ"},"outputs":[],"source":["# Find all named groups\n","\n","# Named Groups.\n","regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(?P<school>\\w{3,})'\n","text = ''' The university of kentucky is the best\n","            basketball team and an ok university.\n","            The University Of Kentucky can be put in \n","            some weird capitalization.  And Kentucky is much better than\n","            the University of Mississippi.'''\n","for m in re.finditer(regex, text):\n","    print(m.groupdict())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9810EEcMpgQZ"},"outputs":[],"source":["'abcabcabc'.replace('a', 'X')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipF5IL2dpgQa"},"outputs":[],"source":["text = 'I love Introduction to Data Science'\n","re.sub(r'Data Science', r'Schmada Schmience', text) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AM1sLuP0pgQa"},"outputs":[],"source":["re.sub(r'(\\w+)\\s([Ss]cience)', r'\\2 \\1hmience', text) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U27sgOz8pgQa"},"outputs":[],"source":["# Let's use it to parse part of a CSV?\n","text = '12,15,22,36,78,33,77,33,45'\n","\n","# Use Regex split command\n","print(re.split(',', text))\n","\n","# Use string split command\n","print(text.split(\",\"))\n","\n","#Use Regex to split into groups...\n","regex = r'(?P<data>\\d*,)'\n","for m in re.finditer(regex, text):\n","    print(m.groupdict())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.8.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
